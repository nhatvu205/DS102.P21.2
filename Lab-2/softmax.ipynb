{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nhập dữ liệu\n",
    "df_softmax = pd.read_csv(\"data.csv\", delimiter = \";\")\n",
    "pd.set_option('display.width', 500)\n",
    "df_softmax.columns = df_softmax.columns.str.strip()\n",
    "\n",
    "# Encoding cho biến target thành ma trận one-hot\n",
    "def encode_target(value: str) -> list:\n",
    "    if value == \"Dropout\":\n",
    "        return [1, 0, 0]\n",
    "    elif value == \"Enrolled\":\n",
    "        return [0, 1, 0]\n",
    "    else:\n",
    "        return [0, 0, 1]\n",
    "\n",
    "# Chuyển đổi 'Target' thành danh sách one-hot\n",
    "df_softmax[\"Target\"] = df_softmax[\"Target\"].apply(encode_target)\n",
    "\n",
    "# Tạo dataframe mới từ danh sách one-hot\n",
    "y_one_hot = pd.DataFrame(df_softmax[\"Target\"].tolist(), \n",
    "                         columns=[\"Dropout\", \"Enrolled\", \"Graduate\"])  \n",
    "\n",
    "# Gộp lại với df_softmax (bỏ cột Target cũ)\n",
    "df_softmax = pd.concat([df_softmax.drop(columns=[\"Target\"]), y_one_hot], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xác định X và y\n",
    "X_softmax = df_softmax.drop(columns=[\"Dropout\", \"Enrolled\", \"Graduate\"]).values\n",
    "y_softmax = df_softmax[[\"Dropout\", \"Enrolled\", \"Graduate\"]].values\n",
    "\n",
    "# Chia dataset thành 3 phần theo tỉ lệ 8:1:1\n",
    "X_train_s, X_temp_s, y_train_s, y_temp_s = train_test_split(X_softmax, y_softmax, test_size=0.2, random_state=42)\n",
    "X_dev_s, X_test_s, y_dev_s, y_test_s = train_test_split(X_temp_s, y_temp_s, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chuẩn hóa dữ liệu\n",
    "scaler_s = StandardScaler()\n",
    "X_train_s = scaler_s.fit_transform(X_train_s)\n",
    "X_dev_s = scaler_s.transform(X_dev_s)\n",
    "X_test_s = scaler_s.transform(X_test_s)\n",
    "\n",
    "# Softmax Regression Class\n",
    "class SoftmaxRegression:\n",
    "    def __init__(self, epochs: int, lr: float) -> None:\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.losses = []\n",
    "        self.metric = []\n",
    "        self.theta = None  # Định nghĩa sẵn để tránh lỗi khi gọi predict() trước fit()\n",
    "\n",
    "    def softmax(self, z: np.ndarray) -> np.ndarray:\n",
    "        exp_z = np.exp(z - np.max(z, axis=1, keepdims=True))  # Tránh overflow\n",
    "        return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
    "\n",
    "    def loss_fn(self, y: np.ndarray, y_hat: np.ndarray) -> float:\n",
    "        y_hat = np.clip(y_hat, 1e-8, 1 - 1e-8)  # Tránh log(0)\n",
    "        return -np.mean(np.sum(y * np.log(y_hat), axis=1))\n",
    "\n",
    "    def accuracy(self, y: np.ndarray, y_hat: np.ndarray) -> float:\n",
    "        y_pred_labels = np.argmax(y_hat, axis=1)\n",
    "        y_true_labels = np.argmax(y, axis=1)  # Giả định y là one-hot\n",
    "        return np.mean(y_pred_labels == y_true_labels)\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        if self.theta is None:\n",
    "            raise ValueError(\"Model chưa được train! Hãy gọi fit() trước khi predict().\")\n",
    "        z = np.dot(X, self.theta)\n",
    "        return self.softmax(z)  # Trả về xác suất của 3 lớp\n",
    "\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray) -> None:\n",
    "        n, d = X.shape\n",
    "        k = y.shape[1]  # Số lớp\n",
    "        self.theta = np.random.randn(d, k) * 0.01  # Khởi tạo nhỏ để tránh gradient lớn\n",
    "\n",
    "        with tqdm.tqdm(range(self.epochs)) as pb:\n",
    "            for e in pb:\n",
    "                pb.set_description(f\"Epoch {e + 1}\")\n",
    "                y_hat = self.predict(X)  # Xác suất softmax\n",
    "                gradient = (1/n) * np.dot(X.T, (y_hat - y))  # Gradient descent\n",
    "                self.theta -= self.lr * gradient  # Cập nhật tham số\n",
    "\n",
    "                loss = self.loss_fn(y, y_hat)\n",
    "                acc = self.accuracy(y, y_hat)\n",
    "                pb.set_postfix({\"loss\": loss, \"acc\": acc})\n",
    "\n",
    "                self.losses.append(loss)\n",
    "                self.metric.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1000: 100%|██████████| 1000/1000 [00:03<00:00, 278.02it/s, loss=0.602, acc=0.761]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy trên tập dev: 0.76\n",
      "Accuracy trên tập test: 0.74\n",
      "Confusion Matrix:\n",
      " [[124  21  16]\n",
      " [ 15  20  33]\n",
      " [ 12  11 190]]\n",
      "Precision (Macro): 0.67\n",
      "Recall (Macro): 0.65\n",
      "F1-score (Macro): 0.66\n"
     ]
    }
   ],
   "source": [
    "# Huấn luyện mô hình\n",
    "model_s = SoftmaxRegression(lr=0.01, epochs=1000)\n",
    "model_s.fit(X_train_s, y_train_s)\n",
    "\n",
    "# Kiểm tra trên tập dev\n",
    "y_pred_dev = model_s.predict(X_dev_s)\n",
    "\n",
    "# Nếu y_dev_s đã là vector nhãn (0,1,2), không cần np.argmax()\n",
    "if y_dev_s.ndim == 1:\n",
    "    y_dev_labels = y_dev_s\n",
    "else:\n",
    "    y_dev_labels = np.argmax(y_dev_s, axis=1)\n",
    "\n",
    "y_pred_dev_labels = np.argmax(y_pred_dev, axis=1)\n",
    "\n",
    "accuracy_dev = np.mean(y_pred_dev_labels == y_dev_labels)\n",
    "print(f\"Accuracy trên tập dev: {accuracy_dev:.2f}\")\n",
    "\n",
    "# Kiểm tra trên tập test\n",
    "y_pred_test_s = model_s.predict(X_test_s)\n",
    "\n",
    "# Nếu y_test_s đã là nhãn số, không cần np.argmax()\n",
    "if y_test_s.ndim == 1:\n",
    "    y_test_labels_s = y_test_s\n",
    "else:\n",
    "    y_test_labels_s = np.argmax(y_test_s, axis=1)\n",
    "\n",
    "y_pred_test_labels_s = np.argmax(y_pred_test_s, axis=1)\n",
    "\n",
    "accuracy_test_s = np.mean(y_pred_test_labels_s == y_test_labels_s)\n",
    "print(f\"Accuracy trên tập test: {accuracy_test_s:.2f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_dev_labels, y_pred_dev_labels)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "precision = precision_score(y_dev_labels, y_pred_dev_labels, average=\"macro\")\n",
    "recall = recall_score(y_dev_labels, y_pred_dev_labels, average=\"macro\")\n",
    "f1 = f1_score(y_dev_labels, y_pred_dev_labels, average=\"macro\")\n",
    "\n",
    "print(f\"Precision (Macro): {precision:.2f}\")\n",
    "print(f\"Recall (Macro): {recall:.2f}\")\n",
    "print(f\"F1-score (Macro): {f1:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
